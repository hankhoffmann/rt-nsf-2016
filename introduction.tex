In recent years, the microprocessor industry has turned to heterogeneous multi-core processor designs for the next generation of embedded systems. By integrating relatively slower, lower-power processor cores with relatively more powerful and power-hungry ones, it is possible to dramatically improve energy efficiency while achieving high performance. %, particularly for the emerging dynamic computing needs seen in many application domains.  
 %the number of cores, it is possible to dramatically improve performance as well as energy efficiency. This trend has brought in a new breed of processors---\textit{many-core with network-on-chip}---which provide unprecedented advantage in terms of performance-per-watt and inter-core communication latency over traditional microprocessor architectures. 
%Per-chip core counts are expected to further increase significantly in the near future. Indeed, Intel and Tilera have both recently released chips with 80 and 100 cores \cite{tilera, intel}. 
%For example, systems processing real-time business transactions have been implemented by Azul Systems \cite{azul} on top of the highly-parallel Vega3 platform, which consists of up to 864 cores.
%air traffic management using sense and avoid, plug-and-play medical operating rooms,
  Such heterogeneous computing platforms are seeing widespread adoption in many cyber-physical systems (CPS), which are more sophisticated and intelligent computing systems that closely interact with the physical world, including advanced automotive systems, medical CPS, and smart robotics. %Dynamic workloads  seen in such systems, such as recognition, mining and synthesis, present great opportunities for heterogeneous multi-core computing. %To enable intelligent automation of an enormous scale, many CPS have to handle a large variety of resource-demanding workloads. Instead of using multiple networked single-core or multicore chips with small core counts, it would be desirable to use only one or few many-core processors that are highly utilized. Particularly for CPS that often have stringent size, weight, and power (SWaP) constraints, there are strong motivations for utilizing many-core processors. Most importantly, their use can significantly enhance computational performance while dramatically reducing the SWaP consumption. 
 For example, the ARM big.LITTLE, which is a heterogeneous computing architecture integrating relatively slow and fast cores, has been widely adopted in the automotive systems~\cite{?}. This heterogeneous computing technology has been used to serve multiple automotive needs such as infotainment as well as advanced driver assistance systems, and is shown to be able to ``deliver exceptional power and performance that aligns to the vision of scalable solutions for automotive customers~\cite{?}. 
  %?cong: may need to add a more compelling example?
 
 %Tilera's 64-core TILE64 processor has been evaluated~\cite{villalpando2010investigation} for use in the real-time hazard detection and avoidance system of the NASA Altair Lunar Lander~\cite{NASA}. The evaluation showed that ``for computer vision and image analysis the TILE64 architecture provides excellent performance''. This many-core platform has been further recommended for other onboard tasks, including spacecraft and instrument control~\cite{villalpando2010investigation}. 

\vspace{-4mm}
\paragraph{Two Fundamentally Conflicting Goals of Heterogeneous Computing in CPS: Timing Correctness and Energy Guarantees.} 
A major challenge of reliably adopting heterogeneous multicore processors in CPS such as automotive systems is the need to ensure predictable real-time correctness (i.e., enabling timing constraints to be analytically validated at design time).  %which is one of the most important tenets in certification required for such safety-critical systems. 
The functional correctness of a CPS hinges crucially upon the temporal correctness, as the control operations depend on the processing of certain environmental sensing and computation tasks. Establishing real-time correctness requires real-time resource allocation methods, whose focus is on judiciously allocating resources to various tasks so that all the required timing constraints can be satisfied. Although traditional real-time resource allocation methods can ensure timing correctness, they often fail to make or mostly ignore energy guarantees, which is another critical goal of equal importance for many CPS due to the stringent  size, weight, and power (SWaP) constraints imposed by such systems (even with sub-components powered by batteries). Energy guarantees would be critical for safety reasons of many systems and in general beneficial for system designers who have a fixed energy budget and want to support the maximum amount of workloads that require real-time correctness within that budget. 

It is quite challenging to simultaneously consider the two goals of achieving real-time correctness and energy guarantees, because they are fundamentally in conflict. 
On one hand, real-time resource allocation methods often need to maximize the resource utilization and make greedy scheduling choices to guarantee timing correctness for the worst case. On the other hand, however, methods that yield energy guarantees typically require scheduling decisions to be energy-efficient for the current case, implying that in some cases it is wise to scale down the voltage and frequency of certain cores or even force them to idle.(?Cong: Best to incorporate Hank's data support and citations herein.? ) 
 A good real-time resource allocation algorithm may yield excessive amount of energy or thermal hotspots on the many-core chip; while energy-aware methods often fail to make real-time guarantees. %Thus, the problem of many-core resource allocation with the goal of jointly achieving real-time and energy guarantees remains largely open. 
  Besides this challenge, the heterogeneity among cores can greatly complicate resource allocation because ``choices'' must be made when selecting the core upon which a task will execute. When jointly considering timing correctness and energy efficiency in the presence of such heterogeneity and dynamic computing needs, resource allocation becomes even more interesting but complicated due to the huge design space of  timing and energy tradeoffs. Resolving these issues will be the focus of this proposal.

\vspace{-2mm}
\paragraph{Proposed approach.} 
Most existing works on real-time resource allocation in heterogeneous computing systems focus on guaranteeing timing correctness (e.g., see \cite{raravi2014task, raravi2013assigning, niemeier2011partitioned} for an overview). %Existing works on energy-efficient real-time resource allocation for homogeneous systems~\cite{?} cannot be efficiently applied herein because 
 A few recent works~\cite{?} focusing on exploring the timing/energy tradeoff space in a heterogeneous computing system made the following critical assumption: all processor cores can operate at max speed all the time while sustaining safely. %, and (\textit{ii}) heterogeneous processor cores exhibit similar variances in power and performance characteristics with respect to dynamic voltage and frequency scaling (DVFS). 
  This assumption unfortunately invalid due to the critical ``dark silicon'' problem, i.e., essentially all processors are over-provisioned and have much larger max compute capacity than they can safely sustain (this has never been true for embedded systems before but it is now~\cite{?}). The thrust of this research is to simultaneously achieve the goals of timing correctness and energy guarantees on heterogeneous computing platforms containing processor cores with varying speeds by answering the following research questions: \textbf{(\textit{i}) how to guarantee timing while running processor cores as slow as possible to respect given energy budgets?}   \textbf{(\textit{ii}) how to quickly detect and avoid timing errors by utilizing the over-provisioned processing capacity in short bursts?} Our proposed research is fundamentally motivated by the observations that (\textit{i}) it is significantly more energy efficient when slowing down processor cores (compared to the race-to-idle strategy), and (\textit{ii}) processor cores cannot operate at max speed all the time and are (sometimes significantly) over-provisioned for what they can sustain safely. (Sec.~\ref{sec:motivation} will provide detailed data support for these observations.) 
  
  ?Cong: the above paragraph needs more work, as I feel I have not concisely and clearly shown the unique angle that was considered in existing works. That invalid assumption made in existing works needs to be re-worked.?

We intend to show that the fundamental timing/energy tradeoffs can be explored by leveraging recent research by the PI's group that has led to a new set of \textit{optimal} resource allocation algorithms for uniform heterogeneous multicore-based systems containing processor cores with varying speeds~\cite{Zhou2014a, Liu1, Liu2, Liu6, Liu7}. These algorithms can analytically guarantee fast and analytically bounded response times for complex workloads implemented using rather general graph-based formalism and executed in a heterogeneous computing system.  %while minimizing the communication latency among tasks with data dependency if allocated to different nodes in the system. 
We will consider such algorithms as the basis for determining the best configurations of resource allocation  strategies and processor cores' dynamic voltage and frequency scaling (DVFS) settings, which are most energy efficient for a given set of workloads. Significant further development is needed that considers the dynamic and heterogeneous performance and energy characteristics exhibited on the processor cores.
 Since there are numerous choices that can be made regarding resource allocation algorithm,  the task-to-core mapping strategy, and DVFS settings, the potential solution space for this problem is vast. Tasks can be allocated for CPU resources globally (i.e., a task can be mapped onto any resource) or via partitioning (a task can only be mapped onto a designated resource). Also, task priorities may be either static or dynamic. %Moreover, mapping schemes may differ according to the metrics we select to optimize (it is less likely to design an ``one for all'' scheme for different considered metrics). 
 The efficiency of DVFS-incurred energy saving can also be different for cores with different speeds. 
 In this project, we propose to carefully evaluate the various alternatives in the space of potential solutions on top of real hardware and determine which configurations are preferable are given workloads. An real implementation-based empirical evaluation is thus a focus of this project.

\vspace{-2mm}
\paragraph{Research objectives.} We will pursue the following four-step plan to accomplish our research goal.
\begin{itemize}
\item \textbf{Step1: Identify the most energy-efficient configurations of resource allocation and DVFS for a given workload that guarantee timing:} We will first design workload mapping and resource scheduling algorithms for processing workloads on a heterogeneous multicore processor. The goal is to  guarantee timing while minimizing energy consumption by running processor cores as slow as possible. For each devised algorithm, formal timing validation tests will be developed.  
\item \textbf{Step 2: Detect and avoid timing errors.} Although slowing down cores may be most energy-efficient, it may cause timing errors more easily (e.g., due to sudden workload bursts). Thus, we will further develop robust mechanisms for quickly detecting and avoiding timing errors. Our main idea is to achieve this goal through exploiting the over-provisioned processing capacity in short bursts.
\item \textbf{Step 3: Carry out overhead-aware schedulability studies.} The research in the first two steps will provide solutions for simultaneously achieving timing correctness and energy guarantees on heterogeneous computing platforms. To evaluate their effectiveness in practice, we will incorporate them in real hardware (using the ARM big.LITTLE architecture) and conduct large-scale overhead-aware schedulability experiments with both synthetic workloads with widely varied parameters and benchmarks. 
 We plan to apply an extensive methodology that is designed for comparing real-time resource allocation strategies in an overhead-cognizant way \cite{clustered, bastoni2010, BBBdissertation}, which is proven to be effective for many real-time application systems. 
\item \textbf{Step 4: Conduct case-studies.} To determine if our proposed methods can be applied in practice, we intend to conduct  case-study evaluations using several specific real-time workloads seen in automotive systems. For example, one such application we will consider is real-time object recognition, which is heavily performed in automotive systems for implementing tools such as collision avoidance and traffic sign recognition. We will evaluate the performance in terms of several specific metrics for using one or more preferable configurations identified in Step~3 to support such workloads. 
\end{itemize}

\paragraph{Qualification.} The PIs are well-qualified to conduct this research. The proposing team has worked on various aspects of real-time systems, heterogeneous multicore computing, and energy optimization in the past years, ranging from theoretical real-time analysis~\cite{?}, real-time operating systems~\cite{?}, heterogeneous multicore architecture~\cite{?}, and energy efficient computing under various computer architectures~\cite{?}. These efforts have resulted in a number of publications accepted by several systems- and architecture-related premium conference and journal venues such as SOSP, RTSS, ISCA, ASPLOS, IPDPS, Micro, PACT, and IEEE Transactions on Parallel and Distributed Systems. 
PI Liu has been working on developing device driver and OS support for heterogeneous real-time systems accelerated by co-processors such as GPUs~\cite{Liu12, liu2009general, liu2008distributed, liu2008pass, liu2007general, liu2008scheduling, liu2008heavyweight, liu2006distributed, liu2009scalable},  resource allocation on heterogeneous platforms~\cite{?}, and real-time schedulability analysis~\cite{Liu1, Liu2, Liu6, Liu7, Liu10, liu2014supporting, elliott1minimizing, hereconfiguration, he2013exploring, Liu3, Liu4, Liu5, Liu9, Liu11, Liu13}.
PI Hoffman at the University of Chicago has rich experience in ?INPUT FROM HANK?