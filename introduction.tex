
 In recent years, the microprocessor industry has turned to heterogeneous multi-core processor designs for the next generation of embedded systems. By integrating relatively slower, lower-power processor cores with relatively more powerful and power-hungry ones, it is possible to dramatically improve energy efficiency while achieving high performance. %, particularly for the emerging dynamic computing needs seen in many application domains.  
 %the number of cores, it is possible to dramatically improve performance as well as energy efficiency. This trend has brought in a new breed of processors---\textit{many-core with network-on-chip}---which provide unprecedented advantage in terms of performance-per-watt and inter-core communication latency over traditional microprocessor architectures. 
%Per-chip core counts are expected to further increase significantly in the near future. Indeed, Intel and Tilera have both recently released chips with 80 and 100 cores \cite{tilera, intel}. 
%For example, systems processing real-time business transactions have been implemented by Azul Systems \cite{azul} on top of the highly-parallel Vega3 platform, which consists of up to 864 cores.
%air traffic management using sense and avoid, plug-and-play medical operating rooms,
  Such heterogeneous computing platforms are seeing widespread adoption in many cyber-physical systems (CPS), which are more sophisticated and intelligent computing systems that closely interact with the physical world, including advanced automotive systems, medical CPS, and smart robotics. %Dynamic workloads  seen in such systems, such as recognition, mining and synthesis, present great opportunities for heterogeneous multi-core computing. %To enable intelligent automation of an enormous scale, many CPS have to handle a large variety of resource-demanding workloads. Instead of using multiple networked single-core or multicore chips with small core counts, it would be desirable to use only one or few many-core processors that are highly utilized. Particularly for CPS that often have stringent size, weight, and power (SWaP) constraints, there are strong motivations for utilizing many-core processors. Most importantly, their use can significantly enhance computational performance while dramatically reducing the SWaP consumption. 
 For example, the ARM big.LITTLE, which is a heterogeneous computing architecture integrating relatively slow and fast cores, has been widely adopted in automotive systems~\cite{armvehicle1, armvehicle2}. This heterogeneous computing technology has been used to serve multiple automotive needs such as infotainment as well as advanced driver assistance systems, and is shown to be able to ``deliver exceptional power and performance that aligns to the vision of scalable solutions for automotive customers~\cite{armvehicle}.''
  %?cong: may need to add a more compelling example?
 
 %Tilera's 64-core TILE64 processor has been evaluated~\cite{villalpando2010investigation} for use in the real-time hazard detection and avoidance system of the NASA Altair Lunar Lander~\cite{NASA}. The evaluation showed that ``for computer vision and image analysis the TILE64 architecture provides excellent performance''. This many-core platform has been further recommended for other onboard tasks, including spacecraft and instrument control~\cite{villalpando2010investigation}. 

\vspace{2mm} \noindent \textbf{Two Fundamentally Conflicting Goals of Heterogeneous Computing in CPS: Timing Correctness and Energy Guarantees.} 
A major challenge of reliably adopting heterogeneous multicore processors in CPS such as automotive systems is the need to ensure predictable timing correctness (i.e., enabling timing constraints to be analytically validated at design time).  %which is one of the most important tenets in certification required for such safety-critical systems. 
The functional correctness of a CPS hinges crucially upon the temporal correctness, as the control operations depend on the processing of certain environmental sensing and computation tasks. Establishing timing correctness requires real-time resource allocation methods, whose focus is on judiciously allocating resources to various tasks so that all the required timing constraints can be satisfied. Although traditional real-time resource allocation methods can ensure timing correctness, they often fail to make or mostly ignore energy efficiency, which is another critical goal of equal importance for many CPS due to the stringent  size, weight, and power (SWaP) constraints imposed by such systems, particularly for those with battery-powered components. Energy guarantees would be critical for safety reasons of many systems and in general beneficial for system designers who have a fixed energy budget and want to support the maximum amount of workloads that require timing correctness within that budget. 

It is quite challenging to simultaneously consider these two goals because they are fundamentally in conflict. 
On one hand, real-time resource allocation methods often need to maximize resource utilization and make greedy scheduling choices to guarantee timing correctness for the worst case. On the other hand, however, methods that yield energy guarantees typically require scheduling decisions to be energy-efficient for the current case, implying that in some cases it is wise to scale down the voltage and frequency of certain cores or even force them to idle. %(?Cong: Best to incorporate Hank's data support and citations herein.? ) 
 A good real-time resource allocation algorithm may yield excessive amount of energy; while energy-aware methods often fail to make timing guarantees. %Thus, the problem of many-core resource allocation with the goal of jointly achieving real-time and energy guarantees remains largely open. 
  Besides this challenge, the heterogeneity among cores can greatly complicate resource allocation because ``choices'' must be made when selecting the core upon which a task will execute. When jointly considering timing correctness and energy efficiency in the presence of such heterogeneity and dynamic computing needs, resource allocation becomes even more complicated and interesting due to the huge design space of exploring timing-energy tradeoffs. Resolving these issues will be the focus of this proposal.

\vspace{2mm} \noindent \textbf{Proposed approach.} 
Most existing works on real-time resource allocation in heterogeneous systems focus on guaranteeing timing correctness (e.g., see \cite{raravi2014task, raravi2013assigning, niemeier2011partitioned} for an overview). %Existing works on energy-efficient real-time resource allocation for homogeneous systems~\cite{?} cannot be efficiently applied herein because 
 A couple of recently conducted works~\cite{liuenergy, colin2014energy} seek to explore timing-energy tradeoffs when designing resource allocation methods for heterogeneous systems. 
 Unfortunately, such works may not be fundamentally energy efficient due to two reasons. First, a similar design philosophy as those designed for homogeneous platforms is being applied. That is, these works make scheduling decisions purely according to timing-related parameters and timing performance, and then seek to apply power management techniques (e.g., dynamic voltage and frequency scaling (DVFS)) on a ``best-effort'' basis to reduce energy consumption. While it is generally more energy-efficient to use heterogeneous processors instead of identical ones, we argue that fundamental energy efficiency due to using a heterogeneous platform cannot be achieved without considering \textit{heterogeneous energy characteristics of tasks and processors as as ``first-class citizen'' parameters when making scheduling decisions}. Second, the existing works made the following critical assumption: all processor cores can operate at max speed all the time while sustaining safely.
  This assumption is unfortunately invalid due to the critical ``dark silicon'' effect, i.e., essentially all processors are over-provisioned and have much larger max compute capacity than they can safely sustain (this has never been true for embedded systems before but it is now~\cite{?}). Motivated by these observations, the objective of this research is to simultaneously achieve timing correctness and energy efficiency on heterogeneous platforms containing processors with varying speeds by: \textbf{(\textit{i}) Identifying the most energy-oriented resource allocation methods that guarantee timing correctness on a heterogeneous platform}. Such methods will consider the heterogeneous energy characteristics of tasks and processors when making scheduling decisions.
   \textbf{(\textit{ii}) Developing aggressive energy-oriented resource allocation methods that exploit dark silicon, where heterogeneous processors have tremendous additional compute capacity that can only be used for short amounts of time}. Such methods would aggressively achieve significant energy savings while being able to avoid timing errors by utilizing the over-provisioned processing capacity in short bursts.
  %Our proposed research is fundamentally motivated by the observations that (\textit{i}) it is significantly more energy efficient when slowing down processor cores (compared to the race-to-idle strategy), and (\textit{ii}) processor cores cannot operate at max speed all the time and are (sometimes significantly) over-provisioned for what they can sustain safely. (Sec.~\ref{sec:motivation} will provide detailed data support for these observations.) 
  
We intend to show that the fundamental timing-energy tradeoffs can be explored by leveraging recent research by PI Liu's research group that has led to a new set of \textit{optimal} resource allocation algorithms for  heterogeneous multicore-based systems containing processors with varying speeds~\cite{Tong14a, Zhou2014a}. These algorithms can analytically guarantee fast and analytically bounded response times for tasks  executed in a heterogeneous computing system.  %while minimizing the communication latency among tasks with data dependency if allocated to different nodes in the system. 
We will consider such algorithms as the basis for determining the most energy-efficient configurations of resource allocation and DVFS settings, which guarantee timing correctness. Significant further development is needed that considers the heterogeneous performance and energy characteristics of tasks exhibited on the processors.
 Since there are numerous choices that can be made regarding processor capacity allocation,  task prioritization and processor selection, and DVFS settings, the potential solution space for this problem is vast. Tasks can be allocated for CPU capacity globally (i.e., a task can be mapped onto any resource) or via partitioning (a task can only be mapped onto a designated resource). Also, task priorities may be either static or dynamic. %Moreover, mapping schemes may differ according to the metrics we select to optimize (it is less likely to design an ``one for all'' scheme for different considered metrics). 
 The efficiency of DVFS-incurred energy saving can also be different for cores with different speeds. 
 In this project, we propose to carefully evaluate the various alternatives in the space of potential solutions on top of real hardware and determine which configurations are preferable for given workloads. An real implementation-based empirical evaluation is thus a focus of this project.

\vspace{2mm} \noindent \textbf{Research objectives.} We will pursue the following four-step plan to accomplish our research goal.
\begin{itemize}
\item \textbf{Step1: Identify the most energy-efficient configurations of resource allocation and DVFS that guarantee timing:} We will design energy-oriented scheduling methods for heterogeneous platforms. The goal is to guarantee timing while minimizing energy consumption. For each devised algorithm, formal timing validation tests will be developed.  
\item \textbf{Step 2: Develop aggressive energy-saving techniques that exploit dark silicon.} 
We will develop new resource allocation techniques that aggressively reduce energy consumption for mixed critical real-time workloads by spending as much time as possible in slower, more energy-efficient states. Timing errors will be avoided by utilizing the over-provisioned processing capacity in short bursts.
\item \textbf{Step 3: Carry out overhead-aware schedulability studies.} The research in the first two steps will provide solutions for simultaneously achieving timing correctness and energy guarantees on heterogeneous computing platforms. To evaluate their effectiveness in practice, we will incorporate them in real hardware (based on the ARM big.LITTLE architecture) and conduct large-scale overhead-aware schedulability experiments with both synthetic workloads with widely varied parameters and benchmarks. 
 We plan to apply an extensive methodology that is designed for comparing real-time resource allocation strategies in an overhead-cognizant way \cite{clustered, bastoni2010, BBBdissertation}, which is proven to be effective for many real-time systems. 
\item \textbf{Step 4: Conduct case-studies.} To determine if our proposed methods can be applied in practice, we intend to conduct  case-study evaluations using several specific real-time workloads seen in automotive systems. For example, one such application we will consider is real-time object recognition, which is heavily performed in automotive systems for implementing tools such as collision avoidance and traffic sign recognition. We will evaluate the performance in terms of several specific metrics for using one or more preferable configurations identified in Step~3 to support such workloads. 
\end{itemize}

\vspace{2mm} \noindent \textbf{Qualification.} The PIs are well-qualified to conduct this research. The proposing team has worked on various aspects of real-time systems, heterogeneous multicore computing, and energy optimization in the past years, including theoretical real-time analysis~\cite{Liu1, Liu2, Liu6, Liu7, Liu10, liu2014supporting,  Liu3, Liu4, Liu5, Liu9, Liu11, Liu13}, real-time operating systems~\cite{elliott1minimizing, Liu12, GPES, zhou2015supporting, Zhou2014a}, heterogeneous multicore architecture~\cite{Zhou2014a, GPES}, and energy efficient computing under various computer architectures~\cite{Liu12}. These efforts have resulted in a number of publications accepted by several systems- and architecture-related premium conference and journal venues such as SOSP, ASPLOS, RTSS, ISCA, Micro, and IEEE Transactions on Parallel and Distributed Systems. 
PI Liu has been working on developing device driver and operating support support for heterogeneous real-time systems accelerated by co-processors such as GPUs~\cite{Liu12, GPES, zhou2015supporting, Zhou2014a},  resource allocation on heterogeneous platforms~\cite{Tong14a, LiuRTSS14a, LiuRTSS15}, and real-time schedulability analysis~\cite{Liu1, Liu2, Liu6, Liu7, Liu10, liu2014supporting, LiuRTSS14b, elliott1minimizing, Liu3, Liu4, Liu5, Liu9, Liu11, Liu13}.
PI Hoffman at the University of Chicago has rich experience in ?INPUT FROM HANK?