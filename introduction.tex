
Recently, the microprocessor industry has adopted heterogeneous multi-core processor designs for embedded systems. Heterogeneous multicores integrate slow, lower-power cores with powerful and power-hungry ones, to provide a wide range of power and performance tradeoffs. %, particularly for the emerging dynamic computing needs seen in many application domains.  
 %the number of cores, it is possible to dramatically improve performance as well as energy efficiency. This trend has brought in a new breed of processors---\textit{many-core with network-on-chip}---which provide unprecedented advantage in terms of performance-per-watt and inter-core communication latency over traditional microprocessor architectures. 
%Per-chip core counts are expected to further increase significantly in the near future. Indeed, Intel and Tilera have both recently released chips with 80 and 100 cores \cite{tilera, intel}. 
%For example, systems processing real-time business transactions have been implemented by Azul Systems \cite{azul} on top of the highly-parallel Vega3 platform, which consists of up to 864 cores.
%air traffic management using sense and avoid, plug-and-play medical operating rooms,
  Such heterogeneous computing platforms are seeing widespread adoption in many cyber-physical systems (CPS) --- computing systems that closely interact with the physical world --- including intelligent automotive systems, medical devices, and smart robotics. %Dynamic workloads  seen in such systems, such as recognition, mining and synthesis, present great opportunities for heterogeneous multi-core computing. %To enable intelligent automation of an enormous scale, many CPS have to handle a large variety of resource-demanding workloads. Instead of using multiple networked single-core or multicore chips with small core counts, it would be desirable to use only one or few many-core processors that are highly utilized. Particularly for CPS that often have stringent size, weight, and power (SWaP) constraints, there are strong motivations for utilizing many-core processors. Most importantly, their use can significantly enhance computational performance while dramatically reducing the SWaP consumption. 
 For example, the ARM big.LITTLE, which is a heterogeneous computing architecture integrating relatively slow and fast cores, has been widely adopted in automotive systems~\cite{armvehicle1, armvehicle2}. This heterogeneous computing technology serves multiple automotive needs including infotainment and advanced driver assistance systems. Succinctly, this processor design has the potential to  ``deliver exceptional power and performance that aligns to the vision of scalable solutions for automotive customers~\cite{armvehicle}.''
  %?cong: may need to add a more compelling example?
 
 %Tilera's 64-core TILE64 processor has been evaluated~\cite{villalpando2010investigation} for use in the real-time hazard detection and avoidance system of the NASA Altair Lunar Lander~\cite{NASA}. The evaluation showed that ``for computer vision and image analysis the TILE64 architecture provides excellent performance''. This many-core platform has been further recommended for other onboard tasks, including spacecraft and instrument control~\cite{villalpando2010investigation}. 

\vspace{2mm} \noindent \textbf{Two Fundamentally Conflicting Goals of
Heterogeneous Computing in CPS: Timing Correctness and Energy
Guarantees.} When timing correctness (i.e., enabling timing constraints to be analytically validated at design time) takes the form of hard real-time
constraints, timing and energy efficiency are fundamentally in
conflict \cite{conflict-book}. The conflict arises because hard
real-time guarantees require reserving resources sufficient for worst
case latency.  In contrast, energy efficiency requires allocating
resources that just meet the needs of the current job.  Even when
worst case resource allocation is coupled with aggressive energy
reduction (e.g., in the form of voltage scaling \cite{Dudani2002} or
sleep states \cite{Huang2009}), this strategy is less energy-efficient
than allocating for the current case --- a fact which has been
demonstrated both analytically \cite{Albers2011,Bansal2011,Irani} and
empirically \cite{LeSueur11,HotPower,Imes2014a,PowerSlope}. Of course,
hard timing guarantees are a requirement for correct operation of
CPS,\footnote{The functional correctness of most CPS hinges crucially upon the temporal correctness, as the control operations depend on the processing of certain environmental sensing and computation tasks} and their strict size, weight, and power (SWaP)
requirements -- as well as common reliance on battery power -- demand
low energy consumption.

\vspace{2mm} \noindent \textbf{Proposed approach.} Establishing timing correctness requires real-time resource allocation methods. Most existing works on real-time resource allocation in heterogeneous systems focus on guaranteeing timing correctness (e.g., see \cite{raravi2014task, raravi2013assigning, niemeier2011partitioned} for an overview). %Existing works on energy-efficient real-time resource allocation for homogeneous systems~\cite{?} cannot be efficiently applied herein because 
 A couple of recently conducted works~\cite{liuenergy, colin2014energy} seek to explore timing-energy tradeoffs when designing resource allocation methods for heterogeneous systems. 
 Unfortunately, such works fail to maximize energy efficiency for two reasons. First, they use the same design philosophy created for homogeneous systems; i.e., they make scheduling decisions based purely on timing-related concerns and then reduce energy consumption on a ``best-effort'' basis. While heterogeneous processors are generally more efficient than homogeneous ones, we argue that fundamental energy efficiency due to using a heterogeneous platform cannot be achieved without \textit{considering heterogeneous energy characteristics of tasks and processors as a ``first-class citizen'' when making scheduling decisions}. Such energy heterogeneity can be dramatic for many workloads (see Sec.~\ref{sec:hardware} for details). Second, the existing works make the following critical assumption: all processor cores can operate at max speed all the time while sustaining safe power dissipation.
  This assumption is unfortunately invalid due to the critical ``dark silicon'' effect; i.e., essentially all processors are over-provisioned and have much larger maximum compute capacity than they can safely sustain\cite{?}. Motivated by these observations, our goal is to simultaneously achieve timing correctness and energy efficiency on heterogeneous platforms by: \textbf{(\textit{i}) identifying the most energy-efficient resource allocation methods that guarantee timing correctness on a heterogeneous platform} and
   \textbf{(\textit{ii}) developing aggressive energy-oriented resource allocation methods that exploit dark silicon, where heterogeneous processors have tremendous additional compute capacity that can only be used for short amounts of time}. Such methods would aggressively achieve significant energy savings while being able to avoid timing errors by utilizing the over-provisioned processing capacity in short bursts.



\begin{comment}

While the conflict between energy and timeliness is fundamental, the
heterogeneity adopted by modern embedded systems greatly complicates
resource allocation by adding complexity the complexity of selecting
the core type upon which a task will execute. When jointly considering
timing correctness and energy efficiency in the presence of such
heterogeneity and dynamic computing needs, resource allocation becomes
even more complicated and interesting due to the huge design space of
exploring timing-energy tradeoffs. Resolving these issues will be the
focus of this proposal.

A major challenge of reliably adopting heterogeneous multicore processors in CPS such as automotive systems is the need to ensure predictable timing correctness (i.e., enabling timing constraints to be analytically validated at design time).  %which is one of the most important tenets in certification required for such safety-critical systems. 
The functional correctness of a CPS hinges crucially upon the temporal correctness, as the control operations depend on the processing of certain environmental sensing and computation tasks. Establishing timing correctness requires real-time resource allocation methods, whose focus is on judiciously allocating resources to various tasks so that all the required timing constraints can be satisfied. Although traditional real-time resource allocation methods can ensure timing correctness, they often fail to make or mostly ignore energy efficiency, which is another critical goal of equal importance for many CPS due to the stringent  size, weight, and power (SWaP) constraints imposed by such systems, particularly for those with battery-powered components. Energy guarantees would be critical for safety reasons of many systems and in general beneficial for system designers who have a fixed energy budget and want to support the maximum amount of workloads that require timing correctness within that budget. 

It is quite challenging to simultaneously consider these two goals because they are fundamentally in conflict. 
On one hand, real-time resource allocation methods often need to maximize resource utilization and make greedy scheduling choices to guarantee timing correctness for the worst case. On the other hand, however, methods that yield energy guarantees typically require scheduling decisions to be energy-efficient for the current case, implying that in some cases it is wise to scale down the voltage and frequency of certain cores or even force them to idle. %(?Cong: Best to incorporate Hank's data support and citations herein.? ) 
 A good real-time resource allocation algorithm may yield excessive amount of energy; while energy-aware methods often fail to make timing guarantees. %Thus, the problem of many-core resource allocation with the goal of jointly achieving real-time and energy guarantees remains largely open. 
  Besides this challenge, the heterogeneity among cores can greatly complicate resource allocation because ``choices'' must be made when selecting the core upon which a task will execute. When jointly considering timing correctness and energy efficiency in the presence of such heterogeneity and dynamic computing needs, resource allocation becomes even more complicated and interesting due to the huge design space of exploring timing-energy tradeoffs. Resolving these issues will be the focus of this proposal.
\end{comment}

% The old ``proposed approach'' paragraph.
\begin{comment}

\vspace{2mm} \noindent \textbf{Proposed approach.} Most existing works on real-time resource allocation in heterogeneous systems focus on guaranteeing timing correctness (e.g., see \cite{raravi2014task, raravi2013assigning, niemeier2011partitioned} for an overview). %Existing works on energy-efficient real-time resource allocation for homogeneous systems~\cite{?} cannot be efficiently applied herein because 
 A couple of recently conducted works~\cite{liuenergy, colin2014energy} seek to explore timing-energy tradeoffs when designing resource allocation methods for heterogeneous systems. 
 Unfortunately, such works fail to maximize energy efficiency for two reasons. First, they use the same design philosophy created for homogeneous systems; i.e., they make scheduling decisions based purely on timing-related concerns and then reduce energy consumption on a ``best-effort'' basis. While heterogeneous processors are generally more efficient than homogeneous ones, we argue that fundamental energy efficiency due to using a heterogeneous platform cannot be achieved without considering \textit{heterogeneous energy characteristics of tasks and processors as a ``first-class citizen'' when making scheduling decisions}. Second, the existing works make the following critical assumption: all processor cores can operate at max speed all the time while sustaining safe power dissipation.
  This assumption is unfortunately invalid due to the critical ``dark silicon'' effect; i.e., essentially all processors are over-provisioned and have much larger maximum compute capacity than they can safely sustain\cite{?}. Motivated by these observations, our goal is to simultaneously achieve timing correctness and energy efficiency on heterogeneous platforms by: \textbf{(\textit{i}) identifying the most energy-efficient resource allocation methods that guarantee timing correctness on a heterogeneous platform} and
   \textbf{(\textit{ii}) developing aggressive energy-oriented resource allocation methods that exploit dark silicon, where heterogeneous processors have tremendous additional compute capacity that can only be used for short amounts of time}. Such methods would aggressively achieve significant energy savings while being able to avoid timing errors by utilizing the over-provisioned processing capacity in short bursts.
  
\end{comment}
  
  
\begin{comment}
We intend to show that the fundamental timing-energy tradeoffs can be explored by leveraging recent research by PI Liu's research group that has led to a new set of \textit{optimal} resource allocation algorithms for  heterogeneous multicore-based systems containing processors with varying speeds~\cite{Tong14a, Zhou2014a}. These algorithms can analytically guarantee fast and bounded response times for tasks  executed in a heterogeneous computing system.  %while minimizing the communication latency among tasks with data dependency if allocated to different nodes in the system. 
We will consider such algorithms as the basis for determining the most energy-efficient configurations of resource allocation and DVFS settings, which guarantee timing correctness. Significant further development is needed that considers the heterogeneous performance and energy characteristics of tasks exhibited on the processors.
 Since there are numerous choices that can be made regarding processor capacity allocation,  task prioritization and processor selection, and DVFS settings, the potential solution space for this problem is vast. Tasks can be allocated for CPU capacity globally (i.e., a task can be mapped onto any resource) or via partitioning (a task can only be mapped onto a designated resource). Also, task priorities may be either static or dynamic. %Moreover, mapping schemes may differ according to the metrics we select to optimize (it is less likely to design an ``one for all'' scheme for different considered metrics). 
 The efficiency of DVFS-incurred energy saving can also be different for cores with different speeds. 
 In this project, we propose to carefully evaluate the various alternatives in the space of potential solutions on top of real hardware and determine which configurations are preferable for given workloads. An real implementation-based empirical evaluation is thus a focus of this project.
\end{comment}

\vspace{2mm} \noindent \textbf{Research objectives.} We will pursue the following four-step plan to accomplish our research goal.
\begin{itemize}
\item \textbf{Step1: Identify the most energy-efficient configurations of resource allocation and DVFS that guarantee timing:} We will design energy-oriented scheduling methods for heterogeneous platforms. The goal is to guarantee timing while minimizing energy consumption. For each devised algorithm, formal timing validation tests will be developed.  
\item \textbf{Step 2: Develop aggressive energy-saving techniques that exploit dark silicon.} 
We will develop new resource allocation techniques that aggressively reduce energy consumption for mixed critical real-time workloads by spending as much time as possible in slower, more energy-efficient states. Timing errors will be avoided by utilizing the over-provisioned processing capacity in short bursts.
\item \textbf{Step 3: Carry out overhead-aware schedulability studies.} The research in the first two steps will provide solutions for simultaneously achieving timing correctness and energy guarantees on heterogeneous computing platforms. To evaluate their effectiveness in practice, we will incorporate them in real hardware (based on the ARM big.LITTLE architecture) and conduct large-scale overhead-aware schedulability experiments with both synthetic workloads with widely varied parameters and benchmarks. 
 We plan to apply an extensive methodology that is designed for comparing real-time resource allocation strategies in an overhead-cognizant way \cite{clustered, bastoni2010, BBBdissertation}, which is proven to be effective for many real-time systems. 
\item \textbf{Step 4: Conduct case-studies.} To determine if our proposed methods can be applied in practice, we intend to conduct  case-study evaluations using several specific real-time workloads seen in automotive systems. For example, one such application we will consider is real-time object recognition, which is heavily performed in automotive systems for implementing tools such as collision avoidance and traffic sign recognition. We will evaluate the performance in terms of several specific metrics for using one or more preferable configurations identified in Step~3 to support such workloads. 
\end{itemize}

\vspace{2mm} \noindent \textbf{Qualification.} The PIs are well-qualified to conduct this research. The proposing team has worked on various aspects of real-time systems, heterogeneous multicore computing, and energy optimization in the past years, including theoretical real-time analysis~\cite{Liu1, Liu2, Liu6, Liu7, Liu10, liu2014supporting,  Liu3, Liu4, Liu5, Liu9, Liu11, Liu13}, real-time operating systems~\cite{elliott1minimizing, Liu12, GPES, zhou2015supporting, Zhou2014a}, heterogeneous multicore architecture~\cite{Zhou2014a, GPES}, and energy efficient computing under various computer architectures~\cite{Liu12}. These efforts have resulted in a number of publications accepted by several systems- and architecture-related premium conference and journal venues such as SOSP, ASPLOS, RTSS, ISCA, Micro, and IEEE Transactions on Parallel and Distributed Systems. 
PI Liu has been working on developing device driver and operating support support for heterogeneous real-time systems accelerated by co-processors such as GPUs~\cite{Liu12, GPES, zhou2015supporting, Zhou2014a},  resource allocation on heterogeneous platforms~\cite{Tong14a, LiuRTSS14a, LiuRTSS15}, and real-time schedulability analysis~\cite{Liu1, Liu2, Liu6, Liu7, Liu10, liu2014supporting, LiuRTSS14b, elliott1minimizing, Liu3, Liu4, Liu5, Liu9, Liu11, Liu13}.
PI Hoffman at the University of Chicago has rich experience in homogeneous\cite{raw1,raw2,raw3,tilera1,tilera2} and heterogeneneous \cite{ASAP,HPEC,ASAP2,ISSoC} processor design as well as operating systems support for managing performance and power tradeoffs \cite{LEO,POET,DynamicKnobs,JouleGuard,PTRADE,ICAC,TCST,HotPower,CPSNA}.